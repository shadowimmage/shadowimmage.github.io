[{"categories":null,"contents":" I spent my sick day today designing a new logo for the site using Inkscape. I knew that it had to be something that was unique, so I went online looking around for resources on designing and producing a logo. I know that SVGs are great, because you will never have scaling issues - if you need a larger version, you can simply export it at higher resolution. Or lower. Or whatever. I found some sites for inspiration as well, since I couldn\u0026rsquo;t think of exactly what I was going for initially.\nThe new design: logobook.com has been really helpful in looking at what kinds of designs you can do with different features or lettering and Logo Design Love was really helpful in getting my head into a good space for designing a logo. Other than that, the first few iterations of designs were just pen-and-paper drawings in my notebook.\nTools Designing a vector graphic is relatively easy if you have a vector graphic editing program. I have known about Inkscape for a while, and this is what I ultimately used. Another tool I found while looking around for vector graphic tools is a browser-based (or downloadable) tool called Vectr. I didn\u0026rsquo;t use Vectr much, but it looks useful if you need really simple tools and don\u0026rsquo;t want to get something as heavyweight as Inkscape. That being said, using Inkscape and it\u0026rsquo;s exceptional grid and guide snapping tools really made designing this logo easy.\nGetting it online In order to fully implement use of the logo, there\u0026rsquo;s several modifications that I had to make, including converting the .svg file to an .ico or .png format that would be browser friendly. Modern browsers support .svg files for page graphics, but most still don\u0026rsquo;t support the format in the favicon space. Only Internet Explorer requires the format be a .ico for the favicon, and most support .png, but in different levels of quality, depending on the browser and age, and if it\u0026rsquo;s a mobile or a desktop browser (not to mention things like consoles with browsers baked in). I didn\u0026rsquo;t know any of that information starting out though, and instead got a good amount of information from this stackoverflow question.\nChanges to Head \u0026lt;!-- new favicon --\u0026gt; \u0026lt;link rel=\u0026#34;apple-touch-icon\u0026#34; sizes=\u0026#34;180x180\u0026#34; href=\u0026#34;{{ \u0026#34;img/apple-touch-icon.png\u0026#34; | absURL }}\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;icon\u0026#34; type=\u0026#34;image/png\u0026#34; sizes=\u0026#34;32x32\u0026#34; href=\u0026#34;{{ \u0026#34;img/favicon-32x32.png\u0026#34; | absURL }}\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;icon\u0026#34; type=\u0026#34;image/png\u0026#34; sizes=\u0026#34;16x16\u0026#34; href=\u0026#34;{{ \u0026#34;img/favicon-16x16.png\u0026#34; | absURL }}\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;manifest\u0026#34; href=\u0026#34;{{ \u0026#34;img/site.webmanifest\u0026#34; | absURL }}\u0026#34;\u0026gt; \u0026lt;link rel=\u0026#34;mask-icon\u0026#34; href=\u0026#34;{{ \u0026#34;img/safari-pinned-tab.svg\u0026#34; | absURL }}\u0026#34; color=\u0026#34;#5bbad5\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;msapplication-TileColor\u0026#34; content=\u0026#34;#da532c\u0026#34;\u0026gt; \u0026lt;meta name=\u0026#34;theme-color\u0026#34; content=\u0026#34;#ffffff\u0026#34;\u0026gt; \u0026lt;!-- end favicon --\u0026gt; This required some minor modifications to the Hugo theme that I\u0026rsquo;ve been building off of by changing part of the navbar to include the new monogram svg. Getting the sizing just right required some custom css, which also had to be included in the html head. I also changed the Hugo params in the config file to reflect that the avatar is an avatar, not an icon, and instead use the icon parameter for the file location of the monogram.\nChanges to Nav \u0026lt;div class=\u0026#34;navbar-header\u0026#34;\u0026gt; + \u0026lt;a href=\u0026#34;{{ \u0026#34;\u0026#34; | absLangURL }}\u0026#34;\u0026gt; + \u0026lt;img class=\u0026#34;navbar-brand\u0026#34; id=\u0026#34;site-logo\u0026#34; src=\u0026#34;{{ .Site.Params.logo | absURL }}\u0026#34; alt=\u0026#34;{{ .Site.Title }}\u0026#34; /\u0026gt; + \u0026lt;/a\u0026gt;  \u0026lt;button type=\u0026#34;button\u0026#34; class=\u0026#34;navbar-toggle\u0026#34; data-toggle=\u0026#34;collapse\u0026#34; data-target=\u0026#34;#main-navbar\u0026#34;\u0026gt; \u0026lt;span class=\u0026#34;sr-only\u0026#34;\u0026gt;{{ i18n \u0026#34;toggleNavigation\u0026#34; }}\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;span class=\u0026#34;icon-bar\u0026#34;\u0026gt;\u0026lt;/span\u0026gt; \u0026lt;/button\u0026gt; \u0026lt;a class=\u0026#34;navbar-brand\u0026#34; href=\u0026#34;{{ \u0026#34;\u0026#34; | absLangURL }}\u0026#34;\u0026gt;{{ .Site.Title }}\u0026lt;/a\u0026gt; \u0026lt;/div\u0026gt; ","permalink":"https://shadowimmage.github.io/post/2018-05-18-logo-design/","tags":["post","hugo","update"],"title":"Logo Design"},{"categories":null,"contents":"Full-stack microservice (really basic frontend in Pug/HTML) that takes a FormData object from a file upload form and returns the file size in bytes as part of a JSON response.\n\nUser Stories  I can submit a FormData object that includes a file upload When I submit something, I will receive the file size in bytes within the JSON response  Code View on GitHub\u0026nbsp;\u0026nbsp; // upload page exports.upload = function (req, res) { res.render(\u0026#39;filesize/upload\u0026#39;) } // File Metadata Microservice - file upload result exports.result = function (req, res) { res.json({ \u0026#39;filename\u0026#39;: req.file.originalname, \u0026#39;size\u0026#39;: req.file.size }) }  Demo View this code live on Heroku\n","permalink":"https://shadowimmage.github.io/post/2018-05-12-filemetadata/","tags":["sample","freecodecamp","javascript","demo"],"title":"File Metadata Microservice"},{"categories":null,"contents":"The challenge here was to create a URL Shortener microservice. It uses a database to associate a short url ID with the original url, and once created, the microservice will redirect visitors of the short URL to the original URL.\n\nExample creation input:\n https://fcc-challenges.herokuapp.com/shortener/new/https://www.google.com https://fcc-challenges.herokuapp.com/shortener/new/http://foo.com:80  Example creation output:\n{ \u0026#34;original_url\u0026#34;:\u0026#34;http://foo.com:80\u0026#34;, \u0026#34;short_url\u0026#34;:\u0026#34;https://fcc-challenges.herokuapp.com/shortener/8170\u0026#34; } Usage:\n https://fcc-challenges.herokuapp.com/shortener/2871  Will redirect to:\n https://www.google.com/  Demo View this code live on Heroku at fcc-challenges.herokuapp.com/shortener/\u0026hellip;\n URL Creation: new/https://www.google.com Retrieval: 2871  Code View on GitHub\u0026nbsp;\u0026nbsp; Shortener // URL Shortener (part1) - Short URL Creator exports.new = function (req, res) { var resData = { original_url: \u0026#39;invalid URL\u0026#39;, short_url: null } resData.short_url = req.hostname + \u0026#39;/shortener/\u0026#39; // console.log(req.url)  var url = req.url.slice(5) // console.log(req.url.slice(5))  if (validUrl.isUri(url)) { resData.original_url = url var collection = req.app.dbConn.getDB().collection(shortUrlCollection) var lastDoc = collection.find().sort({ index: -1 }).limit(1) lastDoc.project({_id: 0, index: 1}).toArray(function (err, documents) { if (err) console.error(err) var insertIndex = 1 if (documents.length \u0026gt; 0) { // console.log(documents[0].index);  insertIndex += documents[0].index } collection.insertOne({ index: insertIndex, url: resData.original_url }, function(err, r) { if (err) console.error(err) resData.short_url += insertIndex res.json(resData) }) }) } else { //end valid url section  res.json(resData) } }  Resolver // URL Shortener (part 2) - Short URL resolver/redirector exports.getId = function (req, res) { if (req.params.id) { var collection = req.app.dbConn.getDB().collection(shortUrlCollection) var shortDestDoc = collection.find({ index: parseInt(req.params.id) }).project({ _id: 0, url: 1 }).toArray(function (err, documents) { if (err) console.error(err) if (documents.length \u0026gt; 0) { res.redirect(documents[0].url) } else { res.end(\u0026#39;Invalid short URL id.\u0026#39;) } }) } else { res.end(JSON.stringify({\u0026#39;error\u0026#39;:\u0026#39;invalid URL\u0026#39;})) } } ","permalink":"https://shadowimmage.github.io/post/2018-05-12-urlshortener/","tags":["sample","freecodecamp","javascript","mongodb","demo"],"title":"Url Shortener Microservice"},{"categories":null,"contents":"The goal for this one is to get return to the user the IP address, language, and operating system of the browser/user making the request.\n\nCode View on GitHub\u0026nbsp;\u0026nbsp; // whoami.js // FreeCodeCamp // Backend Challenge 2 - Get requesting client IP Address exports.who = function (req, res) { var resData = { ipaddress: null, language: null, software: null } resData.ipaddress = req.ip if (req.header(\u0026#39;accept-language\u0026#39;)) { resData.language = req.header(\u0026#39;accept-language\u0026#39;).split(\u0026#39;,\u0026#39;)[0] } if (req.header(\u0026#39;user-agent\u0026#39;)) { var userAgent = req.header(\u0026#39;user-agent\u0026#39;) var lParenIndex = userAgent.indexOf(\u0026#39;(\u0026#39;) var rParenIndex = userAgent.indexOf(\u0026#39;)\u0026#39;) if (lParenIndex \u0026gt; -1 \u0026amp;\u0026amp; rParenIndex \u0026gt; -1) { resData.software = userAgent.substr(lParenIndex+1, rParenIndex-lParenIndex) } } res.json(resData) }  Demo View this code live on Heroku at fcc-challenges.herokuapp.com/api/whoami\n","permalink":"https://shadowimmage.github.io/post/2018-05-12-headerparserms/","tags":["sample","javascript","freecodecamp","demo"],"title":"Request Header Parser Microservice"},{"categories":null,"contents":"The goal is to create a microservice that will take a date string or a unix timestamp and make a JSON response with both versions of the given timestamp / date.\n\nCode View on GitHub\u0026nbsp;\u0026nbsp; // timestamp.js // Challenge 1 - Timestamp conversion UNIX \u0026lt;--\u0026gt; Standard  exports.convert = function (req, res) { var timestamp = req.params.timestamp var resData = { unix: null, natural: null } if (!timestamp) { res.json(resData) } else { const months = [\u0026#39;January\u0026#39;, \u0026#39;February\u0026#39;, \u0026#39;March\u0026#39;, \u0026#39;April\u0026#39;, \u0026#39;May\u0026#39;, \u0026#39;June\u0026#39;, \u0026#39;July\u0026#39;, \u0026#39;August\u0026#39;, \u0026#39;September\u0026#39;, \u0026#39;October\u0026#39;, \u0026#39;November\u0026#39;, \u0026#39;December\u0026#39;] if (isNaN(parseInt(timestamp))) { // is a string  var date = new Date(timestamp) resData.natural = months[date.getUTCMonth()] + \u0026#39; \u0026#39; + date.getUTCDate() + \u0026#39;, \u0026#39; + date.getUTCFullYear() resData.unix = Math.floor(date.getTime() / 1000) } else { // is a number (expect unix time)  var unixDate = new Date(timestamp * 1000) resData.natural = months[unixDate.getUTCMonth()] + \u0026#39; \u0026#39; + unixDate.getUTCDate() + \u0026#39;, \u0026#39; + unixDate.getUTCFullYear() resData.unix = timestamp } res.json(resData) } }  Demo View this code live on Heroku at fcc-challenges.herokuapp.com/\u0026hellip;\n Unix-style input: api/timestamp/1450137600 Timestamp input: api/timestamp/December%2015,%202015 ","permalink":"https://shadowimmage.github.io/post/2018-05-12-timestampms/","tags":["post","sample","freecodecamp","demo"],"title":"Timestamp Microservice"},{"categories":null,"contents":" Gotchas In order of the issue being found:\nIs Strange (Hugo) (Template Logic) Hugo templates use strange logic - for conditional statements, Hugo uses Polish or prefix notation for the operators. This meas that instead of writing if this and that, you have to write if and this that. For more complex arrangements of logical conditions, say for a situation in which you need to check three conditions, you have to write it as: if and (first) ( and (second) (third)) which, in a infix notation style, would have been written if first and second and third.\nHugo uses blackfriday Hugo uses blackfriday as it\u0026rsquo;s markdown engine. This is probably totally fine for most situations, except for when you want to make a list with more than 2 levels. For instance,\n first  second  third    In the above case, blackfriday normally will collapse the second and third levels both into the second level. I say normally because most linters and stye guides specify an indent of 2 spaces for markdown [citation needed]. If you come from github markdown style, then this is likely the case for you. Unfortunately there\u0026rsquo;s an annoying bug in blackfriday that requires that the indent for each level be 4 spaces. If you don\u0026rsquo;t notice this when scanning through the Hugo documentation on content formats, you\u0026rsquo;ll likely run into a situation where you\u0026rsquo;re confused about your list ending up somewhat flattened.\nFortunately, most linters can be configured to have different indent settings. For Visual Studio Code (my current editor of choice), markdownlint can be configured with a .markdownlint.json file in the root of your project directory or in your .vscode\\settings.json workspace settings file. This isn\u0026rsquo;t a show stopper, but for me, wasted some time while I had to dig through to find the issue report in blackfriday and then more time to read the markdownlint documentation and figure out how to reconfigure the indent setting to make sure that my lists in my Hugo site markdown will pass.\nQuestion for later:\nCan I catch this / use markdownlint in CircleCI builds?\nHugo Supports Emoji in Markdown This wasn\u0026rsquo;t super hard to figure out, but could be easier to find info on (I actually think that the Hugo documentation could use a way better table of contents, and better search). I nearly added an emoji css library to my site head in order to support emoji via \u0026lt;i\u0026gt; tags inline in the markdown file, but fortunately found that emoji are natively supported by Hugo, but you have to enable it with the enableEmoji = true setting in the site\u0026rsquo;s root configuration. Once you enable emoji support for content files with that setting, you can easily insert emoji with their names between colons (eg ðŸ˜©).\nProtip: want larger emoji on your page? Have a header with an emoji rather than plain text. The emoji will scale to the predefined scale of the header. (Note: this will also anger the markdownlint gods, as the trailing \u0026lsquo;:\u0026rsquo; isn\u0026rsquo;t allowed)\nðŸ˜„ ","permalink":"https://shadowimmage.github.io/post/2018-05-10-hugo-gotchas/","tags":["post","fyi","note","help"],"title":"Hugo Gotchas"},{"categories":null,"contents":"I woke up late today, so I didn\u0026rsquo;t have time to make coffee. And instead of going to my usual place where I know there\u0026rsquo;s going to be great coffee available, I decided to get a doughnut and some coffee from the doughnut shop. The first warning that this wasn\u0026rsquo;t going to go well was when I got my travel mug back and there was coffee all over the outside of the mug. All day since then I\u0026rsquo;ve been drinking it slowly (8 hours) and it\u0026rsquo;s just been terrible. It\u0026rsquo;s really made me sad, because I paid money for this coffee, and this is Seattle. I could have gone to the Starbucks down the block from this doughnut shop, but instead decided not to in favor of making one stop, rather than two on my way into work.\nI should have just waited longer and gone to my usual place.\n","permalink":"https://shadowimmage.github.io/post/2018-05-10-bad-coffee/","tags":["blog","coffee","fwp","short"],"title":"Bad Coffee"},{"categories":null,"contents":" Built a new site, leaving Jekyll for Hugo, for my github.io page.\nChanges Moved all my old Jekyll files to a new subdirectory in order to maintain access to the old code and posts, and then transition all the content over to the main Hugo site as settings come together. One major advantage of Hugo is that the build process is super fast, so I\u0026rsquo;ve been looking at how to integrate CircleCI with Hugo builds. Fortunately the CircleCI engineering blog has a post on how to get set up doing automated builds via CircleCI.\nCircleCI One of the caveats of using Github Pages for hosting my static content is that I have to have the site content in the master branch. I had already branched my project to start working with Hugo to the hugo branch, with the intent that this branch would eventually merge back with master. After reading a bit more about how Hugo works, it seems that the hugo branch is going to be a permanent feature, with master being overwritten with the content of the /public output from the Hugo build process. The hugo branch will remain indefinitely as the new default branch on the site repository.\nOn the other hand, this will work out fine, as it will let me ser CircleCI up to pull the current hugo branch when updated, and then upon successful build, will be able to push the resulting build back up to the repository\u0026rsquo;s master branch. This automated build process is perfect for what I\u0026rsquo;m hoping to achieve, and will let me get more experience with CircleCI, which I haven\u0026rsquo;t touched in months!\n","permalink":"https://shadowimmage.github.io/post/2018-05-09-new-static-site-with-hugo/","tags":["post","Hugo","update"],"title":"New Static Site with Hugo"},{"categories":null,"contents":"This project was built for Classroom Technologies \u0026amp; Events at the University of Washington.\n\nView on GitHub\u0026nbsp;\u0026nbsp;   Background The University has been updating their course scheduling from an onsite instance of R25 (unable to link because documentation doesn\u0026rsquo;t exist on the internet anymore) - a product from CollegeNET. Part of that process involved moving the scheduling database off-site. This allowed for a new integration to our Slack instance that could contact the R25 web service, now hosted on the CollegeNET servers, rather than secured locally on one of the UW\u0026rsquo;s servers.\nTimeline I came up with the idea for this project around April 18th, 2018, after talking to some colleagues about transitioning other internal tools that leveraged the local SQL database over to the R25 web service after the system transitioned to the cloud. Our department had recently been granted access to the web service, and I had spent the earlier part of the month translating Python scripts that had been digesting local SQL results to talking to the R25 web service and digesting XML instead. I spent about a week researching the possible integrations between Slack and external apps, and decided to use a Slack Slash Command for the integration\u0026rsquo;s implementation.\nImplementation Full details on the README\nTo quickly get up and running I started out with AWS Lambda and getting up to speed with what was necessary to get an AWS Lambda function working on the web. This led me to Serverless as a way of accelerating development and management of AWS resources.\nThe first version of the integration used only one Lambda function, but in order to echo commands back to the user in a channel and also respond later asynchronously, two Lambda functions are required. This is because each Lambda function can only reply to the request / trigger that started it once. If the Lambda function replies to Slack to acknowledge receipt of the command, then it won\u0026rsquo;t be able to reply later once the R25 data has been retrieved and processed. If the Lambda function waits until it\u0026rsquo;s gathered and processed all the R25 data, then it might miss the 3-second window to acknowledge the Slack command, and even if it does reply within the time frame, the confirmation of the command happens after the results are returned to Slack, making the confirmation show up not only late, but out of order. Thus two Lambda functions are required: one to parse and return acknowledge the command and another to query and process the R25 web service data.\nScreenshots Invoking   Invocation\n    Help   Help\n    ","permalink":"https://shadowimmage.github.io/project/slackr25bot/","tags":["project","aws","lambda","sns","slack","UW"],"title":"SlackR25Bot - UW"},{"categories":null,"contents":"I\u0026rsquo;ve been making a lot of progress on the python-LEDSerialController project. There\u0026rsquo;s been a lot to learn about how to run the original command line script with a GUI frontend. I chose to use Tk since it\u0026rsquo;s baked into Python already, and there\u0026rsquo;s nothing to configure to get it working. It doesn\u0026rsquo;t look nearly as nice as something that would come out of using a more advanced UI toolkit, but it\u0026rsquo;s also had a lower bar to entry, despite some drawbacks with Tk\u0026rsquo;s documentation. Googling around for solutions to problems as they arise has proved to be effective though.\nGetting this project to run smoothly has been a challenge because I\u0026rsquo;m using one thread to accomplish everything, which comes with the restriction that nothing can be blocking (at least not for long) without causing UI lag (bad) or causing responsiveness on the LED controller (Arduino) to lag. This is further complicated by the way that I\u0026rsquo;ve built up the Arduino code to allow it to perform animations with the LED strips and check in on the serial buffer.\nAll of this combines to create the following conditions:\n The Arduino only checks in with the computer when it\u0026rsquo;s ready for a new command in between running pattern animations, which depends on the interval setting for the last command that was sent The UI only updates while the Python thread is not blocked or doing anything long-running Updating the Arduino requires checking the computer\u0026rsquo;s serial buffer to see if the Arduino has signaled that it\u0026rsquo;s ready for the next command.  Disadvantages of doing things this way:\n A pattern animation, such as the animated rainbow, will only run for a single cycle, and then stop. More to the point, without any serial input from the host computer, the Arduino will cease to update any LEDs at all. The host computer must continually update the Arduino (controller) with what to do next, including, telling it to do the same thing over again.  Advantages of doing things this way:\n Any updates to state on the Python host program can update the controller with new information as soon as it\u0026rsquo;s ready UI to Controller update delay is minimal UI can remain responsive while the controller is busy and not ready for communication  Timing on the Tk application can be tricky in this situation: checking the serial input as often as possible can push CPU usage to 100%, and accomplishes nothing productive since the Arduino won\u0026rsquo;t be ready for updates that frequently. On the other hand, checking too infrequently will lead to stuttering in continuous patterns, but will leave more time on the host PC for keeping the UI responsive.\nThe way I solved this was to ensure that any blocking actions are only executed when absolutely necessary. In this instance, I can use the pyserial in_waiting property to know when the Arduino has sent data that needs to be checked:\ndef serial_has_waiting(self): \u0026#34;\u0026#34;\u0026#34;Return true if there is serial data in the input buffer - non-Blocking\u0026#34;\u0026#34;\u0026#34; return self.cmdMessenger.comm.in_waiting != 0 Using that method allows me to avoid going into my incoming data handling code before there\u0026rsquo;s anything in the input buffer to read:\ndef getCommandSet(self, src): receivedCmdSet = None logging.debug(src + \u0026#39;: getCommand...\u0026#39;) while (self.cmdMessenger.comm.in_waiting == 0): # blocking - here as a final check before self.c.receive() time.sleep(0.1) receivedCmdSet = self.c.receive() logging.debug(src + \u0026#39;: getCommand complete.\u0026#39;) if (receivedCmdSet[0] == \u0026#34;CMDERROR\u0026#34;): logging.error(\u0026#34;CMDERROR: \u0026#34; + receivedCmdSet[1][0]) logging.debug(receivedCmdSet) return receivedCmdSet The final piece is making a method that will be called for every cycle of the Tk mainloop() - first in main:\nif __name__ == \u0026#39;__main__\u0026#39;: try: if setup(): pre_run_commands() app.after(500, update_controller) # HERE app.mainloop() except KeyboardInterrupt: # Called when user ends process with CTRL+C stop() And within update_controller():\ndef update_controller(): \u0026#34;\u0026#34;\u0026#34;Check the LED Controller, and issue, or re-issue a command as needed\u0026#34;\u0026#34;\u0026#34; if LEDController.serial_has_waiting(): LEDController.repeat() app.after(75, update_controller) # HERE The important part here is the amount of time (in milliseconds) that the app.after() is given for the next check. Initially from main, I have it set at 500ms, since we want to get things going and allow a little time for the UI to get started before we start the serial communication with the Arduino in earnest. Later on, it\u0026rsquo;s reduced to 75ms in update_controller() so that we can have enough time to update the UI, not overburden the CPU, and also be sure to catch input from the Arduino relatively quickly (within about 75ms, which is pretty fast). This balance is fast enough that animations on the Arduino don\u0026rsquo;t perceptibly have a delay in between iterations.\nI might tune these values more, but for now things seem to be running well enough that I can focus on further development of the UI and implementing more advanced actions through the Tk GUI, and eventually (long term) start building out connections to other applications and APIs that would allow the LED strip to react to events from other applications or web services.\n","permalink":"https://shadowimmage.github.io/post/2017-06-21-python-tk-iu-notes-project-update/","tags":["python","gui","update"],"title":"Python Tk UI Notes, Project Update"},{"categories":null,"contents":"First Post!\nLearning how to set up Jekyll on GitHub Pages is actually a little harder than I was expecting from the outset. Mostly because most of the things that you need to set up Jekyll for local development, and a lot of the things that come prepackaged with it aren\u0026rsquo;t actually necessary for running it on GitHub Pages.\nHere is the Gemfile content for this page when I first started and got things working:\nsource \u0026#34;https://rubygems.org\u0026#34; ruby RUBY_VERSION # ... gem \u0026#34;jekyll\u0026#34;, \u0026#34;~\u0026gt; 3.3\u0026#34; gem \u0026#34;jekyll-theme-slate\u0026#34; # If you have any plugins, put them here! group :jekyll_plugins do gem \u0026#34;jekyll-feed\u0026#34; gem \u0026#34;github-pages\u0026#34; end This is actually a mix of what you end up with when you create a site from scratch on GitHub Pages using the theme chooser with an empty repository. And it\u0026rsquo;s also different from the one you\u0026rsquo;d get by starting locally using the Jekyll Quick-start guide. While the Quick-start mentions this helpful guide to getting started using Jekyll on GitHub Pages (which I worked through and found to bve educational in getting things set up), it doesn\u0026rsquo;t make use of the nice (an easy to use) templates / themes that you can select through the GitHub Pages repository settings. To do that, you need to use the template HTML / CSS from the theme baked into GitHub Pages by copying default.html according to this article on GitHub Help.\nOnce you have your theme working, and you have a working website that you can reach, and your content is showing up the way you expect, you can begin customizing and adding in plugins, custom CSS, etc.\nOne final issue I ran into was a dependency issue with the Gemfile.lock vs. the Gemfile when trying to set up this site to use CircleCI (more for fun getting to know CircleCI than anything else). The issue was that when I created a local Jekyll deployment for testing with the same repository as the one I was using for GitHub Pages, I had been making a lot of ignorant changes to my Gemfile. There were conflicting entries between the two and my resolution (since there wasn\u0026rsquo;t much here to break yet) was to rename Gemfile.lock to Gemfile.lock.old left my Gemfile as it was, and then reran bundle install, which will regenerate Gemfile.lock, without any conflicts between them.\nOnce that was ironed out, CircleCI was able to complete without errors, but without a circle.yml, it also didn\u0026rsquo;t have any tests to run in order to say anything about the state of the project. So I put together a basic configuration:\nmachine:ruby:version:2.4.0dependencies:post:-bundleexecjekyllbuildtest:post:-bundleexechtmlproofer./_site--check-html--disable-external The above is basically lifted from the CircleCI page in the Jekyll docs, plus specifying the ruby version that\u0026rsquo;s currently being used by GitHub Pages.\nAnother issue that I ran into trying to get this page to build on CircleCI was this Jekyll issue (#2938). So I had to add \u0026ldquo;vendor\u0026rdquo; to the exclude list - this was not immediately clear (since I hardly know YAML at all) because it\u0026rsquo;s listed on the fixes as \u0026gt; yml \u0026gt; exclude: [vendor] \u0026gt; But if you want it in a YAML list, it needs to be noted as\nexclude:-vendor-....otherexcludes.... So after all that, do I have a passing build? No.\nhtmlproofer found some \u0026lt;a href=\u0026quot;#\u0026quot;\u0026gt; placeholder tags and failed.\nBut at least now it\u0026rsquo;s failing because of something I wrote, rather than because of a configuration issue!\nSuccess and progress.\n","permalink":"https://shadowimmage.github.io/post/2017-05-25-learning-jekyll-and-getting-started-with-github-pages/","tags":["jekyll","update","learning"],"title":"Learning Jekyll and Getting Started with Github Pages"},{"categories":null,"contents":"We have a hammer drill that has a vacuum collector attachment, and we wanted a collector that could use different kinds of filters. I took the existing dust collector and designed an exact replacement that would take any kind of 3M respirator filter as the filter element. This allows using different kinds of filters and for the filters to be replaced. The parts involved were manually reverse-engineered on paper with the device and a set of good digital calipers. The replacement parts were designed in Autodesk Fusion360 and 3D printed on a Prusa i3 MK2.\n\nReverse Engineering a Device Digital calipers are infinitely helpful when trying to reverse engineer or copy a physical object with 3D CAD and 3D Printing. Dimension all the parts on a drawing and then use those measurements to create the 3D model in CAD. This was a challenging project, and one of the most complex models that I\u0026rsquo;ve ever had to engineer. The result was a device that was a perfect 1:1 fit in the overall vacuum body.\nChallenges The original filter device didn\u0026rsquo;t need to have any moving parts, and the filter was build into the wall between the chamber and the outlet. For my design I had to get a round filter to attach to a rectangular shaft, and also position the connection point somewhere where the filter could be folded around into the rectangular space of the dust chamber. Using a lofted profile allowed me to blend the rectangular outlet port into a circular tube to connect with the filter body. This worked well and maintained equal or greater volume between the filter connection point and the outlet port (no pinch point for the airflow).\nThe other challenge was designing a sliding joint that would hopefully be tight enough to seal, keeping the dust contained within the chamber and maintaining vacuum pressure. It took several test prints with small cut-away sections of the sliding joint between the two halves to get the tolerances just right to be tight without being loose or impossible to slide. This was definitely helped by making sure that the 3D printer was well calibrated and consistent throughout the entire print.\nDrawings   Reference measurements taken from the original device\n      Reference measurements taken from a sample filter scan\n     Results Below is a rendering of the 3D model from Fusion360. Unfortunately I neglected to take any photos of the finished 3D print.\n    ","permalink":"https://shadowimmage.github.io/project/dustcollector/","tags":["project","3d printing","uw","fusion360"],"title":"Dust Collector - UW"},{"categories":null,"contents":" Summary I\u0026rsquo;m a person living in Seattle, Washington where I work for Classroom Technology \u0026amp; Events (CTE) at the University of Washington.\nMy interests are manifold, from art to computer science. I\u0026rsquo;ve built my skillset from a position of curiosity, using an analytical approach to problems and their possible solutions, always researching what I don\u0026rsquo;t know. I love to learn. I solve difficult problems by combining my learning and experience into novel approaches and solutions.\nðŸ›  Skills Languages, Tools, \u0026amp; Operating Systems Python   Javascript  Node   git  virtualenv  Linux  Windows   Databases MySQL  MongoDB   SQL Server  GraphQL    Frameworks Vue   React   Django    BI Tools Tableau   Knime    Architecture Serverless   IP Networking  RESTful APIs   Cloud Platforms \u0026amp; Technologies AWS   Heroku   Continuous Integration / Continuous Delivery    Experience  Senior Computer Specialist  University of Washington   May 2016 - Present  Seattle, WA     Create business intelligence solutions and tools, informing service improvement. Develop software tools to automate processes, saving hundreds of hours of staff time. Manage communications and outreach campaigns with wide customer base. Manage and maintain 400+ desktop and laptop computers.     Program Support Supervisor  University of Washington   Aug 2013 - May 2016  Seattle, WA    Managed a team of help desk analysts, including hiring and training. Performed Tier 2 and 3 support and maintenance of HD AV Systems adn infrastructure while providing excellent customer support and service. Certified in Biamp Audio DSPs and Crestron DigitalMedia.\n    Lead Help Desk Analyst  University of Washington   Apr 2009 - Jun 2013  Seattle, WA         Education  BFA, 3D4M  University of Washington School of Art   2008 - 2013  Seattle, WA     Undergraduate degree culminating in a synthesis of computer science and art in the form of live drawing robots within the gallery space and finished works displayed in the gallery. Coursework involved (but was not limited to) CS fundamentals, data structures and algorithms, networking, databases, studio art, sculpture, and acoustics.    Additional Details Check me out on Linkedin\u0026nbsp;\u0026nbsp;\n","permalink":"https://shadowimmage.github.io/page/about/","tags":null,"title":"About me"},{"categories":null,"contents":" This file exists solely to respond to /search URL with the related search layout template.\nNo content shown here is rendered, all content is based in the template layouts/page/search.html\nSetting a very low sitemap priority will tell search engines this is not important content.\nThis implementation uses Fusejs, jquery and mark.js\nInitial setup Search depends on additional output content type of JSON in config.toml ` [outputs] home = [\u0026quot;HTML\u0026quot;, \u0026quot;JSON\u0026quot;] \\`\nSearching additional fileds To search additional fields defined in front matter, you must add it in 2 places.\nEdit layouts/_default/index.JSON This exposes the values in /index.json i.e. add category ` ... \u0026quot;contents\u0026quot;:{{ .Content | plainify | jsonify }} {{ if .Params.tags }}, \u0026quot;tags\u0026quot;:{{ .Params.tags | jsonify }}{{end}}, \u0026quot;categories\u0026quot; : {{ .Params.categories | jsonify }}, ... \\`\nEdit fuse.js options to Search static/js/search.js ` keys: [ \u0026quot;title\u0026quot;, \u0026quot;contents\u0026quot;, \u0026quot;tags\u0026quot;, \u0026quot;categories\u0026quot; ] \\`\n","permalink":"https://shadowimmage.github.io/search/","tags":null,"title":"Search Results"}]